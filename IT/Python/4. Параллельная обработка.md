как заставить выполняемую программу использовать ресурсы CPU максимально эффективно
* синхронная программа - код выполняется последовательно, в случае если программа ждет (i/o, обращение к api/БД) поток блокируется, cpu не нагружается, переключения PVM на другие задачи не происходит
* асинхронная - как только происходит "ожидание", python переключается на выполнение других задач программы
	* в общем виде асинхронность <> многопоточность (в 1 еденицу времени может работать 1 поток, но в случае ожидания, может выполнять код из другого потока, это реализация асинхронности в python, но в других ЯП: Java/C/Rust потоки одного процесса могут выполняться одновременно на нескольких ядрах CPU)
	* честная параллельная работа в py возможна только в рамках нескольких процессов, в рамках потоков - только асинхронная . Дополнительный поток (интерпретатор) можно создать через *multiprocessing*
## Потоки и процессы
общие понятия для computer science. Встроены в ОС, используются в ЯП.
**Process**
* изолированное окружение (пространство имен, данные и ресурсы) для выполнения программы. 1 процесс не может "случайно" изменить данные другого
* 1 процесс = 1 интерпретатор (PVM/GIL/память). Даже либа *multiprocessing* создает дочерние процессы по таким правилам
* выполняются на разных ядрах CPU (разделение на уровне ОС) => выполняются параллельно
* переключение между процессами - большие накладные расходы - медленно
* сложный обмен данными (Inter-process communication)
**Tread**
* набор инструкций в рамках одного *Process*, объединенных для последовательного выполнения
* общее окружение (пространство имен, данные и ресурсы)
* простое переключение между *Tread*
* реализация параллельной работы CPU над потоками сильно разница между ЯП + есть несколько концептуальных способов организации такой работы
### GIL
глобальная блокировка интерпретатора в CPython
* PVM в 1 единицу времени выполняет только 1 *Tread* вне зависимости от количества ядер доступных *Process*
* т.е. py код в рамках 1 *Tread* выполняется свсегда в 1 поток на 1 ядре CPU
* параллельная обработка нескольких *Tread* невозможна
* возможна реализация асинхронного владения CPU когда 1 tread освобождает CPU другому если он чего-то ждет (i/o, обращение к api/БД)

## Реализация в Python
### Асинхронность потоков
все крутиться вокруг *coroutines*, *event loop* и специальных операторов *async/await*
* вызов синхронных операций внутри асинхронных блокирует асинхронное выполнение т.е. будем ждать завершение операции => выполнение кода перестает быть асинхронным

**Coroutine**
особый тип объекта в python (разновидность генератора)
```python
async def process(): # async - помечаем функцию как асинхронную
    data = await fetch_data()  # await - ожидаем выполнение корутины
    print(data)
```

**async** - ключевое слово, которое превращает объект в корутину, может быть применен к:
* *функция* - возвращает корутину, через return, асинхронный генератор. Для вызова f-ии требуется *await*
	* невозможно сделать lambda f-ю асинхронной
```python
async def my_func():
	return await some_io_object()
```

* *асинхронный генератор* - если async функция вернет обычный генератор через yield, f-я будет синхронной
```python
async def my_func(n):
	for i in range(n):
		await asyncio.sleep(1)
		yield 1

async for i in my_func(3):
	print(i)
```
* *асинхронный контекстным менеджерам*
```python
async with db_connection as c:
	data = await c.fetch('SELECT * FROM table')
```
* *асинхронные итераторы*  -  для асинхронного перебора коллекции
```python
async for i in range(5):
	await asyncio.sleep(1)
	print(i)
```
* *асинхронные comprehensions* - объект коллекции
```python
[await my_func(item) async for item in async_iterator]
```
**await** - ключевое слово которым помечается awaitable объект: корутина (все что перечисленно выше), таск из event loop
* await перед корутиной значит что интерпретатор не будет его ждать и блокировать выполнение, он продолжил работу, и вернется к выполнению с этого места
* await можно воспринимать как точку переключения интрепретатора на другие таски
#### Event Loop
пул корутин для асинхронной обработки
* он наполнен футурами (*Future* - обертка над *Task*, которая в своб очередь обертка над корутиной) - Task хранит состояние: pending, running, done).
* обработка выполняется в 1 поток - см. GIL
* когда корутина достигает await какого-то объекта, её обработка останавливается и берется следющая
* когда в ожидаемый объект вызывает callback и event loop продолжает с ней работать (при условии что подошла её очередь)
в 1 процессе можно создать несколько Event Loop но единовременно активен только 1

```python
import asyncio  
  
async def fun1(x):  
    print(x**2)  
    await asyncio.sleep(4)  
    print('fun1 завершена')  
  
async def fun2(x):  
    print(x**0.5)  
    await asyncio.sleep(3)  
    print('fun2 завершена')  
  
async def main():  
    task1 = asyncio.create_task(fun1(4))  # create_task - помещаем в Event Loop таски
    task2 = asyncio.create_task(fun2(4))  
  
    await task1  # ждем завершения тасок
    await task2  
  
asyncio.run(main()) # запускаем выполнение тасок в Event Loop
```

todo https://habr.com/ru/articles/667630/
	 https://habr.com/ru/articles/671798/
	 https://habr.com/ru/articles/774582/