## PULL/PUSH подходы

**Глоссарий**
**Data contract** - соглашение (формат, периодичность, схема, SLA) между поставщиком и потребителем об условиях обмена данными.
**Backfill** - возможность выгрузить историю из СИ за произвольный период
**Обратная совместимость** - возможность обрабатывать в data piplane данные с предыдущей версией схемы
**Логическая репликация** - метод репликации использующий репликационные идентификаторы (PK)
**Физическая репликация** - метод репликации использующий побайтовое копирование (Master-Slave в PG)
**Гетерогенная среда** - сеть с разными протоколами передачи данных + узлы с разным набором ОС и софта (разные версии БД). Антоним - **Гомогенная среда**
**Kafka Connect** - сервис Kafka реализующий потоковую передачу данных между 
**Каноническая модель данных** - унифицированный формат и схема данных, неспецифичная и абстракция, максимально гибкая для разных участников "данных"
#### PULL - приходи и забирай данные 
* **Batch копирование** - прошли и забрали кусок из мастер системы (nill)
	- - нагружаем источник
	* - работаем по расписанию
	* + можем выгружать ретроспективу
	* - зависим от схемы мастер системы
	* + возможны контракты данных
	* - плохо масштабируется с шардированными БД
	* + не требует доработок мастер системы
	* - однопоточная
	* + поддерживаются view
* **CDC** (bods)
	* + не нагружаем источник
	* + не требует доработок мастер системы
	* - ограничение коробочных CDC 
	* - требует наличие PK у сущности
	* - много лишнего оверхеда для обработки
	* + многопоточная
	* - зависим от схемы мастер системы
	*  - не можем выгрузить ретроспективу (мастер система не хранит лог репликации долго)
* **API** - приходим в API и просим данных (nifi)
	* - работаем по расписанию
	* + есть контракт
	* - не контролируем форматы данных (каждая API уникальна)
	* + реализация МС скрыта от ETL
	* +- не всегда возможна выгрузка ретроспективы
* **Выгрузка из шины** - consume из kafka (unicorn/nifi)
   источник пушит в шину для бизнес приложения, ETL подключается к этой же шине и забирает те-же данные что и бизнес приложение 
	* + имеем контракт, но не свой, а бизнес приложения
	* + реализация МС скрыта от ETL
	* + хорошо масштабируется
	* - зависим от формата данных бизнес приложения
	* - не имеет backfill

**Выводы про PULL:** 
* нет контрактов, либо они "слабые"
* нет абстракций, часто ETL должен знать реализацию МС
#### PUSH - тук тук вот наши данные
* **Синхронный вызов ETL API** - источник готовит данные, отправляет в API
	* + есть контракт
	* + параллельная обработка
	* - ETL API должно быть high availability
	* - МС должна реализовать логику ретраев и всего такого  
* **Загрузка в шину ETL** - специально выделенная шина под ETL (sdp)
	* + есть контракт
	* + хорошо масштабируется
	* + реализация МС скрыта от ETL
	* + параллельная обработка
	* - не имеет backfill
	* + унификация подходов, единые правила формата, инкремента и т.д. для всех МС
	* - нужен системный анализ ETL и МС
	* - дополнительная когнитивная нагрузка на МС
**Выводы про PUSH:** 
* почти всегда native-contract
* многие риски переходят на МС
* масштабируемость
* реализации МС и ETL скрыты друг от друга
## CDC
сервисы логической репликации
### Oracle Golden Gate
* чтение изменений DML из redo лога, DDL и DML(blob/clob) - из undo или таблицы, преобразование в SQL и применение в другой БД
* обязательно наличие PK или Unique index
* не копирует Glob/Blod типы (в теории может но это грузит master)
* не нагружает Master
* в гомогенной среде возможно первичная онлайн синхронизация, в гетерогенной - нет
* для проверки целостности/согласованности передачи нужна специальная софтина Veridata. Также она может использоваться для проверки формата/схемы
* некоторые специальные типы данных совсем не поддерживаются
* поддерживает репликацию с RAC (кластеризация ora db), но переключать GG на нужный узел нужно руками
* высокая производительность N терабайт/час
* отдельная платная админка, работает только для oracle продуктов
* на каждый чих своя лицензия, разные сборки: for Big Data, for Kafka, for Oracle, for NonOracle
* стоит как золотой мост (20k$ CPU/year на 2020)

**Классическая (старая) схема репликации**
	*EXTRACT* - захватывает изменения в source_db и складывают их в trail файлы (Oracle, MsSQL, MySQL, PG, Cassandra, KafakConnect)
	*DATA PUMP* - передает по сети их файловой системы source_db до файловой системы target_db
	*REPLICAT* - применяет данные к target_db Oracle, MsSQL, MySQL, PG, Cassandra, KafakConnect, GP, HDFS)
Последняя версия 23ai поддерживает все что можно, даже векторные БД (по заявлениям)
текущая микросервисная архитектура куда сложнее, куча сервисов, все общается через RestAPI

### Debezium
* open source, на Java
* невысокая производительность по сравнению с Oracle GG
* не поддерживается часть типов данных (например, XML/JSON, CLOB)
* может читать из MongoDb, MySql, PG, OraDB, MSSql, Cassandra и др.
* распределенный, хорошо масштабируется
* при развертывании и настройки до prod уровня нужно поплясать
* состоит из
	* коннектора Debezium (Kafka source connector) к db источника (MySQL - читает из binlog и PG - читает из потока логической репликации)
	* Apache Kafka - куда source connector коннектор пишет поток, по умолчанию 1 таблица - 1 топик
	* далее можно читать из топика, можно использовать kafka sink connector для записи в таргет
![[Pasted image 20240612152644.png|1200x300]]
Физически **Kafka Connect**,**Apache Kafka** и **Schema Registry** (для avro схем) - разные кластера на N нод. На **Kafka Connect** создаются Debezium коннекторы, которые в случае падения одной ноды - перезапустятся на другой. При первом подключении коннектор работает в режиме **snapshot.mode** переливая всю таблицу в топик, затем переключается на чтение из журнала

есть реализация **Debezium Server**:
![[Pasted image 20240612153517.png|600x300]]

## ESB
 Enterprise Service Bus или корпоративная шина данных
 **Опр:** связующее ПО обеспечивающее централизованный, обмен сообщениями между сервисами.
 * мульти протокольный - разные сервисы общаются разными протоколами и разными форматами сообщений, все это в единой шине
 * маршрутизация - шина отвечает за доставку сообщения конечному потребителю
 * ESB сама опрашивает сервисы на предмет готовых к отправке сообщений
 * на смену концепции ESB пришла Service Mesh (т.к. микросервисам не удобно общаться через единую шину)
 * слабосвязанная асинхронная модель - отдельный сервис не ждет ответа о доставке своего сообщения
 * ESB также может заниматься трансформацией протоколов и сообщений по условиям
