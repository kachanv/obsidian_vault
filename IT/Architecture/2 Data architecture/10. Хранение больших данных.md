## Глоссарий

## Storage - тип файловой системы
стандарт индустрии - распределенные файловые системы

### HDFS
**Опр:** Hadoop Distributed File System
* файловая система предназначенная для поблочного хранения больших файлов между узлами кластера
* все блоки имеют один размер (кроме  последнего) => равномерное распределение (hdfs сам равномерно распределяет по узлам тупо деля файл на равные куски)
* есть N реплик для каждого блока - настраиваемый параметр на уровне файла
* модификация файла не поддерживается, только удаление и запись
* запись в файл может осуществлять только 1 процесс
* есть N data nodes - хранят данные и 1 name node - хранит мету и расположение файлов/блоков по узлам
* HDFS может применятся отдельно от hadoop как распределенная файловая система
* HDFS надстраивается поверх файловой системы сервера т.е. является виртуальной ФС
* в настоящий момент морально устарела и использование идет на спад, предпочтения отдаются *S3*
* основным преимуществом была дешевизна железа
* листинг (структура папок отражает структуру данных) - одна из главных проблем тк отсюда идет ограничение на транзакции, хранение метаданных

### S3
**Опр:** *Simple Storage Service*. Плоское объектное хранилище поддерживающее API стандарта Amazon S3
* доступ к фалу/объекту осуществляется по ключу. Часто ключ = URL
* нет иерархии в ФС, она плоская. Объекты объединяются в бакеты.
* нет понятия файла или каталога. Есть понятие объекта
* на бакеты навешиваются ACL, так управляют правами
* строго говоря s3 это не файловая система в классическом понимании
## File format
в каком формате хранить файлы в распределенной файловой системе
### Parquet
* колоночный, хранит вложенные структуры, хорошо сжимаемый (поддерживается *Spark* и *Impala*)
* Данные и таблицы (DDL) не изменяемы
* Каждая таблица представляется кучей файлов с метаданными, блоками, патрициями, статистикой, индексами и колонками данных.
* Много где поддерживается
* Вычитываются только нужные столбцы
* значения 1 колонки идет рядом те можно читать последовательно

### RCFILE
**Опр:** Record Columnar File. row-column level storage. 
* Оптимизирован под пропуски данных. 
* Делит файл на группы строк, затем каждый столбец пишет в свой файл

### ORC
**Опр:** Optimized Row Columnar
* хранит в блоках статистику min,max и т.п. 
* Хранит типы данных рядом с данными что позволяет быстро и хорошо сжимать. 
* Можно менять DDL в определенных пределах. 
* Данные делятся на пачки (у каждой пачки есть 3 блока: индексы, данные и footer) пачки на столбцы.
* По каждому столбцу своя статистика и индексы (крайние значения), которые используются для пропуска данных. 
* Поддержка ACID, лучше сжимаем.

### Avro
* бинарный строчный формат, схема, может работать с динамическими типами, данные хранятся в бинарном виде, 
* схема в json
* схема может эволюционировать
* легковесный: JSON дублирует структуру в каждом сообщении, AVRO держит структуру в схеме а передает только данные
* Уровни совместимости схем: 
	   BACKWARD - можно удалять поля, добавлять nullable поля, сравнение идет с последней версией схемы, первыми схему обновляют консюмеры,                     
	   FORWARD - можно добавлять поля, удалять nullable поля, сравнение идет с последней версией схемы, первыми схему обновляют продюсеры
	   FULL - можно добавлять/удалять nullable поля, сравнение идет с последней версией схемы, любой порядок обновления
	   NONE - нет проверки на совместимость
	   для каждого уровня (кроме NONE) есть вариант с проверкой всех версий схем а не последней
* может предаваться вместе с данными, может лежать во внешнем или локальном хранилище (реджестри) и передавать с данными только название схемы и её версию (например в confluence первый байт сообщения - версия схемы из реджестри)
* 4 кодека сжатия
* возможно ли десериализовать avro схемой с другой версией

### SEQUENCEFILE
* простой бинарник, пара ключ-значение. 
* Хорошо жмется
* оптимален для map-reduce но это row level storage со всеми вытекающими

## Table format
в каком формате хранить таблицы в  файлах. (у файла при этом свой формат)

### Iceberg
* icebetg - стандарт, чтобы его заадоптить и получить весь функционал нужно следовать всем спецификациям
* позволяет в распределенной файловой системе работать с таблицами как в реляционной БД (транзакции, индексы, схемы, update и пр.)
	* при этом *File Format* может не позволять менять данные (*Parquet*)
* таблица - спосок data файлов + meta файлов, которые не обязаны лежать в 1 дирректории. И тех и тех файлов очень много
* концепция iceberg - неизменные snapshot-ы data и meta файлов. Благодаря этому есть версионность данных снимками и возможность отката
* поиск data файлов идет через meta файлы - отдельный для каждой таблицы т.о. можно иметь много копий фалов метаданных (делать snapshot, branch, транзакции)
* партицирование производиться по функции от поля таблицы - т.о. оптимизатору необязательно явно указывать поле партицирования в предикате
* есть откат изменений и версии таблиц (branch) - благодаря snapshot-ам
* эволюция схем таблиц (не нужно переливать таблицу при смене DDL) - старые данные будут лежать со старым DDL. Если нужно поменять на всем объеме - переливка или Compaction
* эволюция партицирования - можно менять схему партицирования налету - новые данные по новому, старые по старому. Аналогично DDL
* 2 варианта менять данные: 
	* *Copy-on-write* (COR создать новый файл)
		* файл при изменении целиком перезаписывается => быстрое чтение, пухнущие data файлы
	* *Merge-on-read* (MOR создать файл с инкрементом)
		* *Delete file* - файл который создается при MOR рядом с data файлами, содержит удаленные строки, помогает избегать перезаписывание больших файлов при изменении. Есть 2 политики: 1 хранит удаленные ключи и при чтении каждый раз накладывается предикат, 2 хранит название файла и номер удаленной строки. Второй тип более производительный на чтение, первый - на запись
* Update как всегда самая дорогая операция, по сути выполняется как upset в RAM. 
* У нас применяется COR	
* наиболее зрелые движки для compute - *Spark* и *Trino*
* порядок чтения: каталог->мета->данные
* порядок записи: каталог->данные->мета
* на каждое изменение данных содается *manifest file* в котором описано что изменилось (верхнеуровнево)
* используются оптимистичные блокировки с оптимизацией. Некоторые операции можно выполнять параллельно с чужими изменениями. Поддерживается уровень изоляции на уровне 1 таблицы, но не на все операции. В случае невозможности обеспечить изоляцию запись или чтение просто падает.
* в data файлах могут быть экземпляры с сортировкой и без неё
* в iceberg все пути - абсолютные т.е. нельзя просто скопировать данные в другой бакет. Нас не касается - это сложность для платформы
#### Что влияет на произодительность
* количество и размер файлов (data и meta), порядок сортировки, политика изменения данных: *Copy-on-write* или *Merge-on-read*, способ партиционирование
* *размер файлов data* - хорошо когда 128-512 мб. на data файл (обычно их много). Writer обычно не заморачиваются, просто пишут новый файл, если пачки маленькие - получается много маленьких файлов, а это плохо для оптимального чтения. На стороне Storage нужно периодически делать Compaction iceberg файлов. Есть несколько политик Compaction: binpack, sort, z-order sort. Compaction создает новый снэпшот, старые не трогает.
* *размер файлов data* - rewrite_manifest - создает новый единый файл meta данных. Как compaction только для meta файлов
* *партицирование* - поддерживает неявное (hidden) партицирование: не по столбцу, а по выражению. При смене выражения партицирования нужно сделать Compaction т.к. старые данные не перезапишуться автоматически. Нет партицирования по нескольким столбцам, нет drop partition, нет rolling partition.
* *политика изменения данных* - COR и MOR
#### Метаданные
* лежит в metadata files
* то-что написано в статистике - не гарантируется на все 100, по идее тот кто пишет статистику берет на себя обязательства что он пишет правильные величины
#### Каталог
* хранит мету тублиц, статистику
* популярные реализации - HMS, AWS Glue - но это все устарело. Сейчас стандарт индустрии - REST каталог. Nessie по сути единственный, кто поддерживает REST и используется в enterprise
* для разных движков compute могут использоваться разные каталоги
### HUDI
