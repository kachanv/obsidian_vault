## Глоссарий

## Storage - тип файловой системы
стандарт индустрии - распределенные файловые системы

### HDFS
**Опр:** Hadoop Distributed File System
* файловая система предназначенная для поблочного хранения больших файлов между узлами кластера
* все блоки имеют один размер (кроме  последнего) => равномерное распределение (hdfs сам равномерно распределяет по узлам тупо деля файл на равные куски)
* есть N реплик для каждого блока - настраиваемый параметр на уровне файла
* модификация файла не поддерживается, только удаление и запись
* запись в файл может осуществлять только 1 процесс
* есть N data nodes - хранят данные и 1 name node - хранит мету и расположение файлов/блоков по узлам
* HDFS может применятся отдельно от hadoop как распределенная файловая система
* HDFS надстраивается поверх файловой системы сервера т.е. является виртуальной ФС
* в настоящий момент морально устарела и использование идет на спад, предпочтения отдаются *S3*
* основным преимуществом была дешевизна железа
* листинг (структура папок отражает структуру данных) - одна из главных проблем тк отсюда идет ограничение на транзакции, хранение метаданных

### S3
**Опр:** *Simple Storage Service*. Плоское объектное хранилище поддерживающее API стандарта Amazon S3
* доступ к фалу/объекту осуществляется по ключу. Часто ключ = URL
* нет иерархии в ФС, она плоская. Файлы объединяются в бакеты.
* нет понятия файла или каталога. Есть понятие объекта
* на бакеты навешиваются ACL, так управляют правами
* строго говоря s3 это не файловая система


## File format
в каком формате хранить файлы в распределенной файловой системе

### Parquet
* колоночный, хранит вложенные структуры, хорошо сжимаемый (поддерживается *Spark* и *Impala*)
* Данные и таблицы (DDL) не изменяемы
* Каждая таблица представляется кучей файлов с метаданными, блоками, патрициями, статистикой, индексами и колонками данных.
* Много где поддерживается
* Вычитываются только нужные столбцы
* значения 1 колонки идет рядом те можно читать последовательно

### RCFILE
**Опр:** Record Columnar File. row-column level storage. 
* Оптимизирован под пропуски данных. 
* Делит файл на группы строк, затем каждый столбец пишет в свой файл

### ORC
**Опр:** Optimized Row Columnar
* хранит в блоках статистику min,max и т.п. 
* Хранит типы данных рядом с данными что позволяет быстро и хорошо сжимать. 
* Можно менять DDL в определенных пределах. 
* Данные делятся на пачки (у каждой пачки есть 3 блока: индексы, данные и footer) пачки на столбцы.
* По каждому столбцу своя статистика и индексы (крайние значения), которые используются для пропуска данных. 
* Поддержка ACID, лучше сжимаем.

### Avro
* бинарный строчный формат, схема, может работать с динамическими типами, данные хранятся в бинарном виде, 
* схема в json
* схема может эволюционировать
* легковесный: JSON дублирует структуру в каждом сообщении, AVRO держит структуру в схеме а передает только данные
* Уровни совместимости схем: 
	   BACKWARD - можно удалять поля, добавлять nullable поля, сравнение идет с последней версией схемы, первыми схему обновляют консюмеры,                     
	   FORWARD - можно добавлять поля, удалять nullable поля, сравнение идет с последней версией схемы, первыми схему обновляют продюсеры
	   FULL - можно добавлять/удалять nullable поля, сравнение идет с последней версией схемы, любой порядок обновления
	   NONE - нет проверки на совместимость
	   для каждого уровня (кроме NONE) есть вариант с проверкой всех версий схем а не последней
* может предаваться вместе с данными, может лежать во внешнем или локальном хранилище (реджестри) и передавать с данными только название схемы и её версию (например в confluence первый байт сообщения - версия схемы из реджестри)
* 4 кодека сжатия
* возможно ли десериализовать avro схемой с другой версией

### SEQUENCEFILE
* простой бинарник, пара ключ-значение. 
* Хорошо жмется
* оптимален для map-reduce но это row level storage со всеми вытекающими

## Table format
в каком формате хранить таблицы в  файлах. (у файла при этом свой формат)

### Iceberg
* позволяет в распределенной ФС работать с таблицами как в реляционной БД (транзакции, индексы, схемы, update и пр.)
	* при этом *File Format* может не позволять менять данные (*Parquet*)
* таблица - спосок файлов с данными, которые не обязаны лежать в 1 дирректории
* поиск файлов с данными идет через файл метаданных - отдельный для каждой таблицы т.о. можно иметь много копий фалов метаданных (делать snapshot, branch, транзакции)
* транзакция не может коммититься сразу более чем на 1 таблицу
* партицирование по функции от поля - т.о. оптимизатору необязательно явно указывать поле партицирования в предикате
* есть откат изменений и версии таблиц (branch)
* эволюция схем таблиц (не нужно переливать таблицу при смене DDL)
* эволюция партицирования (менять схему партицирования налету - новые по новому, старые по старому)
* 2 варианта менять данные: *Copy-on-write* (перезаписать файл) и *Merge-on-read* (создать файл с инкрементом). Update как всегда самая дорогая операция, по сути выполняется как upset в RAM.
* наиболее зрелые движки для compute - *Spark* и *Trino*
* *Delete file* - файл содержит удаленные строки, помогает избегать перезаписывание больших файлов при изменении. Есть 2 вида, 1 хранит удаленные ключи, 2 хранит название файла и номер удаленной строки. Второй тип более производительный.
* порядок чтения: каталог->мета->данные, порядок записи - наоборот, только сначала читаем каталог
* на каждое изменение данных содается *manifest file* в котором описано что изменилось (верхнеуровнево)
* используются оптимистичные блокировки с оптимизацией (некоторые операции можно выполнять параллельно с чужими изменениями)
* в файлах таблички могут быть экземпляры с сортировкой и без неё
* в iceberg все пути - абсолютные т.е. нельзя просто скопировать данные в другой бакет

#### Метаданные
* лежит в metadata files
* то-что написано в статистике - не гарантируется на все 100, по идее тот кто пишет статистику берет на себя обязательства что он пишет правильные величины
### HUDI
