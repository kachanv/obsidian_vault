**Глоссарий**
**Staging area** - дословно "перевалочный пункт". Место где происходит временное хранения и обработка данных. Обычно пользователи не имеют сюда доступ.
**ODS** - хранилище операционных данных. Динамически меняются по мере изменения данных в СИ в отличии от центрального DWH, т.е. не версионно.
**DM** - витрины подготовленные для анализа
**Cost Per Storage** - оценка стоимости хранения единицы информации (где и как хранить данные дешевле)
**Shared-Nothing** - тип архитектуры при которой исполнители используют изолированные (только свои собственные) ресурсы
**Data Gravity** - данные притягивают данные. Которые в конечном счете становится невозможно куда либо переместить.
**Master Data Management** (MDM) - управление основными данными.
**Reference Data Management** (RDM) - управление справочными данными
**Master Data** (MD) — данные, предоставляющие контекст для сведений о бизнес-деятельности. Сюда же относятся и идентификаторы основных бизнес сущностей. Не транзакционны, это отдельный тип данных по версии DAMA.
## Подходы к общей организации хранилищ данных
2 высокоуровневые концепции построения и развития batch хранилищ данных
### Архитектура Инмона
*Bill Inmon*, 1990
в простонародии - Фабрика (но не Data Fabric, это другое)
* модель хранилища предметно ориентирована т.е. абстракции - крупные сущности бизнеса, а не функции и приложения. 
* абстракции унифицированы и связаны по единым правилам (унифицированные перекодировочные значения, наименования, суррогатные ключи)
* данные не изменяемы - в случае изменения фиксируется новая версия т.е. остается ретроспектива изменений т.е. хронология изменений - снимками
* присутствуют как сводные данные (агрегаты) так и записи на транзакционном уровне
* присутствую исторические данные - даже те, которых нет в СИ
* в основе DWH - нормализованная модель (3NF), над ней строятся денормализованные витрины
*  проектирование начинается с анализа бизнес-объектов и их атрибутов. Данные подгоняются под эти абстракции.
![[Pasted image 20240618214410.png]]
### Архитектура Кимбалла
*Ralph Kimball*, 1996
многомерное хранилище
* отказ от нормализации
* факты с СИ выгружаются в деморализованном, преобразованном виде: большие денормализованные таблицы фактов с числовыми метриками в проекции на измерения. Множество таблиц фактов проецируются через шину на общие объединяющие измерения.
* возможна при условии что множественные бизнес процессы используют одни данные и унифицированные абстракции измерений и фактов
* функциональная роль DWH шире т.к. включает в себя подготовку и загрузку и представление данных
* в основе DWH - витрины, для маршрутизации по витринам используются *confirmed dimensions* - согласованные измерения т.е. измерения пронизывающие несколько фактов.
* не исторична в *STG*, но может быть исторична *DM* (снимками, SCD1, SCD3)
* по определению является *dimensional model* (star schema)
* проектирование начинается с анализа бизнес-процессов и их атрибутов. Данные подгоняются под эти абстракции.
* есть область STG, где происходит преобразование, очистка сырых данных, объединение разных источников, перед попаданием в Data Mart
* модель крайне похожа на модель отчетов в BI
* Типичный проект выглядит так: вы пишете ETL для объединения источников данных из разных систем, накапливаете данные в STG, а затем используете (снова!) инструмент ETL для моделирования данных в области DM.
![[Pasted image 20240620185340.png]]
Модель появилась на запрос от потребителей о более быстрой поставке т.к. классический Inmon предполагает 3NF в DWH, что долго дорого. Модель была прорывной т.к. считалось что денормализованные данные не имеют права на существование. 
![[Pasted image 20241123181446.png|700x400]]
#### Data Warehouse Bus Matrix
**Опр:** показывает взаимосвязь всех фактов и измерений хранилища в виде матрицы (таблицы). В столбцах-измерения, в строках - факты. На пересечении- флаг связи. Нужна для описания функционала хранилища. Позволяет оценить через какие измерения и пересечения измерений можно анализировать факт.
## Подходы к организации хранения (Storage)

![[Screenshot_886.png|900x450]]

### Data Marts
**Опр:** денормализованная, готовое для анализа под задачи определенного бизнес юнита (*DW* в модели *Инмона* или DM в модели *Кимбалла*)
* потенциальное небольшое количество источников
* объект готов для анализа но невысокая гибкость, трудно сматчить с другими *DM*
* ETL для обработки и приведения сырых данных к витрине
* оптимизирован под быстрое создание витрин из сырых данных и запросы к витринам
* содержит данные из "традиционных" транзакционных источников, приведенных к реляционному виду
* витрины обычно не ретроспективны, только текущая картина
* *Cost Per Storage* может быть разным, но обычно это реляционные СУБД
* *compute* и *storage* не разделяются
### Data Warehause 
**Опр:** централизованное, структурированное, обработанное, закрепленное моделью хранилище данных всего предприятия (DW в модели Инмона)
* ELT для обработки и приведения данных к модели
* потенциально большое количество источников
* затраты времени и ресурсов на обработку данных по пайплайнам
* для анализа необходимо собрать DM из объектов модели
* оптимизирован под приведение данных с разных СИ к единому виду и маппинг сущностей dwh между собой
* содержит данные из "традиционных" транзакционных источников, приведенных к реляционному виду
* модель содержит ретроспективу данных (историчность бизнесовая, техническая или снимками)
* высокий *Cost Per Storage* (обычно это MPP СУБД из дорогого железа)
* *compute* и *storage* не разделяются
### Data Lake
**Опр:** централизованный репозиторий необработанных и неструктурированных данных
* оптимизирован под запись и хранение данных
* широкий набор форматов хранения, сжатия и импорта данных
* некоторая (меньшая) часть данных структурируется и складывается *ETL* инструментами в *DWH* для "классического" анализа
* данных настолько много что их физически не положить в реляционную БД, только в распределенную ФС с куда более низкой *Cost per Storage*
* места куда данные складываются "про запас", чтобы не потерять
* содержит данные из любых источников, транзакционных и нет (не или слабоструктурированные данные, голос, картинки, видео)
* появляются новые пользователи которым не нужны структурированные, предобработанные данные
* низкий *Cost Per Storage* (облака или распределенные ФС из относительно дешевых серверов)
* отдельная проблема таких больших хранилищ (*Dl* и *DLH*) - хранение семантики данных (владельцы, зависимости и пр.)
* фишка в том, что данные грузятся как есть и всё что есть, особо не заморачиваясь над форматом и фильтрацией.
* *ELT* - имеется ввиду что T-финальный этап. Изначально данные извлекаются и грузятся как есть.
* подходит для хранения и *ML*
* некоторые облачные провайдеры предлагают функцию авто выключения DL, если данные не пишутся/читаются.
* в большинстве случаев на Hadoop экосистеме
* можно считать много, но не быстро (если считать на ноду)
* зоопарк компонентов - проблемы с надежностью и экспертизой
### Data Lake House
**Опр:** симбиоз DL и DWH
* впервые предложено Databricks
* все сырые данные (структурированные и нет) сваливаются в DL
* слой метаданных - ключевое место в архитектуре, тут самое сложное
	* содержит мету всех объектов DL
	* реализует транзакционность (ACID). Что критично т.к. многие инструменты поставки работают через *stream* и параллельно аналитики пишут запросы.
	* поддерживает изменяемость и каталогизацию данных
	* реализует индексирование и поддержку схемы данных в DL
	* поддержка схем и целостности данных (принудительно)
	* средства аудита, правовая модель, менеджмент ресурсов.
	* все это с помощью специальных [[10. Хранение больших данных|Table Format]]
* появляется слои STG - для временного размещения структурированных и очищенных данных и DWH, c данными готовыми для анализа.
* низкий *Cost Per Storage* (по аналогии с *DL* т.к. storage тут аналогичен)
* пока это скорее концепция, коробочных решений нет
* разделение *compute* и *storage*. Хранение дешевое и постоянное. Ресурсы расчета - дорогие и разворачиваются по запросу.
* позволяет объединить *batch* и *stream* обработку одним storage
* т.к. данные хранятся в распределенной файловой системе - доступны инструменты массово параллельной обработки (Map-Reduce, Spark, Tez, [Flink](https://bigdataschool.ru/wiki/flink), и т.п.)
* на данный момент существуют 3 open source проекта, которые помогут организовать этот самый уровень метаданных и превратить DL в DLH: [Delta Lake](https://bigdataschool.ru/blog/what-is-delta-lake.html), Apache Iceberg и Hudi. Также есть платный облачный Databricks
### Virtual Data Warehouse (VDW)
**Опр:** распределенное хранение на СИ
- виртуализация данных вместо ETL - не надо физически перемещать данные из СИ в отдельный аналитический контур через ETL и прочее
- есть слой метаданных, хранящий всю информацию обо всех СИ (*Data Catalog*)
- VDW - прокси инструмент, который позволяет проводить аналитику, использующий физические данные на СИ (trino) используя мету о обо всех СИ
- данные должны быть примерно одинаково структурированы на всех СИ
- не нужна систематическая бизнес аналитика (много минусов, по производительности, изоляции)
- данные всегда свежие
## Архитектура Data Product компаний
когда централизованное хранилище становится bottleneck-ом
### Data Fabric (DF)  
`ткань данных` 2015 год
 **Опр:**  архитектурный подход к организации, управлению и инфраструктуре данных в компании. Концепция распределенной работы с данными. Это не про организацию DWH, это про управление данными в компании.
- подходит для цифровых Data центричных компаний, где быстрое создание и монетизация цифровых *data продуктов* - главный приоритет.
- позволяет объединить все источники данных: *Data Lake*, БД, облака и т.п.
- над данными во всех СИ создается слой мета-данных. Это технологический слой, который занимается управлением данных и доступом к ним (*Data Catalog*).
- микросервисная архитектура, где потребитель и источник данных связаны сквозной интеграцией, с единым стандартом API: что позволяет быстро реагировать на изменение данных.
- стандарт *API* единый - он дает пользователям унифицированный интерфейс к данным.
- для очистки, унификации и сопоставления данных используется *ML*.
- *DF* не владеет данными, она предоставляет платформу для доступа.
- нет единого хранилища данных, нет ETL, данные анализируются там, где они есть. (Если они есть в *DL*, они анализируются там).
- над слоем данных находится интеграционный слой - то самое унифицированное API, которое получает доступ ко всем данным всех источников.
- над ним стоит слой мета данных, где можно отследить происхождение, зависимости данных, понять где что брать.
- над ним строится слой визуализации и менеджмента, через который можно обращаться к данным
- обычно подход DF реализуется внедрением готовых коммерческих платформ данных: *Arenadata EDP* (Enterprise Data Platform).
- *MDM* происходит на уровне компании, а не отдельных систем чтобы реализовать единое управление идентификаторами бизнес сущностей.
- подход не описывает многие вопросы *Data Governance* (кто владеет, кто отвечает, кто контролирует)
### Data Mesh  
`сеть данных` 2019 год
 **Опр:**  архитектура распределенных data pipeline в компании, децентрализованные данные с централизованным управлением, стандартами, инфраструктурой (*Self-Service*)
- средства *Data Quality* тоже как *Self-Service*
- различные наборы данных должны полностью управляться отдельными командами в разных бизнес-областях
- продукты данных каждой доменной команды должны быть обнаруживаемыми, совместимыми
- данные рассматриваются как продукт - *Data as a Product*
- инфраструктура самообслуживания данных представляет собой платформу
- в каждом домене отдельная команда владеет данными, отвечает за них, управляет ресурсами в т.ч. вычислительными
- особое внимание в подходе уделяется культуре данных, мол все должны быть преисполнены данными
- централизованные домены мета данных и управления данными *(Data Catalog*, *Data Government*)
- как выглядит процесс: в компании зарождается Data продукт, владелец продукта идет к доменам и каждый домен отдельно реализует ETL в свой домен и отвечает за него, владелец продукта объединяет данные доменов и отвечает за логику объединения.
- ответственность между участниками закрепляется в *Data Contract*
- *Data Mesh* - больше про процессы, чем про технологии.
- большой вопрос к безопасности данных.
- решает часть проблем в международных компаниях относительно локальных законов о приземлении данных.
#### 4 основных понятия
* **Data Domain.** Способ определить где начинаются и заканчиваются корпоративные данные имеющие отношение к бизнес области компании. Пришло из Domain Driven Design (DDD)
* **Data Product.** Данные, в любом виде, реально приносящие пользу компании  (API, отчет, таблица или dataset в DL). Какие угодно данные, из которых бизнес извлекает пользу. К данным применяется продуктовое решение, это такой же продукт как и все остальные. 
* **Data Platform** (Self-Service). Задача DE домена, при помощи Data Platform превратить данные из ресурса в продукт. Но могут разрабатываться и внутренние инструменты. Экосистема инженерных продуктов для работы с данными - Data Catalog, SS ETL, SS Ingest, Data Quality и пр.
* **Data Governance.** Клей связывающий домены от расползания. Единые политики, стандарты проектирования и разработки. Управление ресурсами. 

### MOR & COW
**Опр:** подходы в lake хранилищах как обновлять данные. те делать Update
* **COW** - copy on write - 
* **MOR** - merge on read - 
## Источники
* https://www.microsoft.com/en-us/sql-server/blog/2014/07/30/transitioning-from-smp-to-mpp-the-why-and-the-how/
* https://habr.com/ru/companies/cedrusdata/articles/729004/
* https://www.ibm.com/docs/en/iis/11.7?topic=topologies-parallel-processing
* https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%81%D1%81%D0%BE%D0%B2%D0%BE-%D0%BF%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0
* Клеппман Мартин - Высоконагруженные приложения. Глава 10. Пакетная обработка
* https://www.holistics.io/books/setup-analytics/kimball-s-dimensional-data-modeling/