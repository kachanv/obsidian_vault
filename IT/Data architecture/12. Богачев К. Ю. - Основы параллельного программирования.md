# CISC и RISC-процессоры
* процессор читает и выполняет инструкции из пямяти. Инструкции - очень простые действия, и их набор ограничен процессором.
* инструкции — это просто числа
* процессор оперирует над данными в регистре (и не только), регистр - очень быстрая память. Для инструкций - отдельный регистр. 
* **ISA** - Instruction Set Architecture, комбинайция инструкций и регистров процессора
* код программ компилируются в инструкции процессора, которые зависят от ISA.
* CISC и RISC - архитектуры процессора (кэш, регистры и наборы команд)
* новейшие архитектуры мимикрируют под обе: CISC бедет какие-то фичи из RISC и наоборот, далее речь про ванильные аръитектуры.
* **ALU** - arithmetic logic units, устройство выполняющее арифметические операции
* каждое обращение CPU к RAM занимает 20 тактов простоя, это из-за того что частота RAM намного ниже. Ускорение RAM:
	* кэш в RAM
	* увеличение блоков памяти RAM => чтение пачки за раз
	* конвеер для доступа к RAM
* **семафор** - mutex
## CISC
*Complex Instruction Set Computer*
* старее RISC, один из приципов - экономия памяти т.к. она была дорогой на момент создания архитектуры
* инструкция в теории не имеет ограничений на длинну, в случае чего скидывается в память
* упор на сложные команды отчасти делался в угоду разработчикам которые в то время писали на assembler
* x86 - Intel, AMD. x86 - интелектуальная собственность Intel
* регистров меньше
* инструкции разбиваются на микропрограммы для переиспользования, которые сохраняются на ROM (если не влезают в регистр)
* инструкции имеют доступ к диску 
* инструкции могут содержать длинный набор команд (взять из регистра, сложить, записать)
* синхронная работа в рамках инструкции. Никакие действия не совершаются со следующей, пока полностью не будет выполнена текущая инструкция
* гипертрейдинг - аппаратные потоки, когда длинные иснтрукции разделяются на микрокод. Это позволяет делать конвеер, но у RISK получается лучше т.к. нет оверхеда.
## RISC
*Reduced Instruction Set Computer*
* ARM - RISC. Apple M1. ARM - тоже компания 
* иснтрукция - 32 bit число
* инструкции проще и меньше, но их много
* 1 инструкция  - 1 цикл CPU
* много регистров, чтобы не обращаться к памяти. Таблица регистров управляет их адресацией.
* архитектура оптимизирована для компиляторов, а не для людей как CISC
* инструкции не имеют доступ к памяти, только к регистру (сложение, умножение, сдвиг)
* конвеер инструкций, аля очередь. Т.К. инструкции маленькие, можно предположить движение очереди и выполнять за такт несколько действий, в отличие от больших команд CISC т.о. обеспечивается некая асинхронность.
* необходимы более сложные компиляторы, чтобы оперировать большим количеством регистров
* т.к. команды проще, нужно меньше транзисторов для процессора
* активно использует кэш т.к. маленькие инструкции требуют более чатый доступ к регистрам, доступ к кэш намного быстрее 
# Cache
* кэш - это не регистр, это отдельная очень быстрая память для сохранения результатов повторяющихся инструкций и данных регистров последних инструкций
* интегрирован в кристалл чипа CPU
* их много, каждый аппаратно разделен
* аппаратно близко находится к тому устройству, с которым работает
* маленький но очень быстый
* у каждого ядра свой кэш
* энергозависимый, хранится в SRAM (память с произвольным доступом)
* работает с той же частотой что и устройство, для которого предназначен
* разделяется на уровни, чем меньше уровень тем меньше и быстрее кэш
	* L0 - для операций ALU, хранит микрооперации, выполняемые за 1 такт
	* L1 - для операций ALU, хранит инструкции, десятки КБ 
	* L2 - обобщённый блок хранения, хранит данные и инструкции, в 2-4 раза медленее L1, 5 тактов для доступа, хранит сотни КБ
	* L3 - кэш межпроцессорного взаимодействия, от 2 до 32 МБ, открыт доступ для всех ядер CPU, в 6 раз медленее L1
* данные постоянно перемещаются между уровнями
* в поисках данных CPU обходит кэш, хотя это зависит от конкретной модели
# Многопроцессорные архитектуры
ключевая дилема: как организовать многопроцессорный доступ к разделяемым ресурсам без блокировок ? А никак, любой ресурс синхронизации - разделяемый. Ядро CPU которое собирается завладень ресурсом и произвести чтение-изменение-запись устанавливает значение семафора и блокирует его, остальные ждут.
## Задачка с умножением n на n матриц
AxB=C
**варианты расчета**
* цикл по строкам C - A берем из кэша, B из памяти
* цикл по столбцам С - А берем из кэша, B из кэша если влезет
* разбить С на квадраты N идем по столбцам - А и B берем из кэша
* аналогичен предыдущему + используем конвеер: увеличим длинну линейного учатка, считая сразу все члены матрицы С где участвуют одни и те же члены матриц A и B

последний варинат даёт 14x приорст производительности в сравнении с первым

# Latency
относительная величина задержки различных операций.
величины приведены в наносекундах
* обращение к L1 - 1
* обращение к L2 - 4
* обращение к mutex при разделяемых ресурсах - 17
* обращение к RAM - 100
* последовательное чтение из RAM 1 Mb - 10 000
* отправить 2 Kb по сети - 1 600
* чтение с SSD 4 Kb random reed - 20 000
* чтение с SSD 1 Mb последовательно - 1 000 000
* чтение с HDD 1 Mb последовательно - 5 000 000
* чтение через сеть 1 Mb последовательно - 10 000 000
* поиск диска - 10 000 000
* передача TCP пакета между континентами - 150 000 000

**Таким образом, можно читать:**
* последовательно с HDD со скоростью ~200 МБ в секунду
* последовательно с SSD со скоростью ~1 ГБ в секунду
* последовательное чтение из оперативной памяти со скоростью ~100 ГБ в секунду (скорость серийного чтения)
* последовательно из 10 Гбит/с Ethernet со скоростью ~1000 МБ в секунду

источники
* https://habr.com/ru/companies/selectel/articles/542074/
* https://static.googleusercontent.com/media/sre.google/ru//static/pdf/rule-of-thumb-latency-numbers-letter.pdf
* глава 2,3,4,5