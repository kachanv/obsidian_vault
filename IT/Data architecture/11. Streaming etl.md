Архитектура потоковой передачи данных
# Общие понятия
## Cемантики доставки
- *exactly once* - гарантированная доставка одного единственного сообщения
- *at least once* - гарантированная доставка сообщения, но возможны дубли
- *at most once* - отправил и забыл, гарантирована отправка, доставка не гарантируется
всё это из-за асинхронной работы, синхронно обраратывать и фиксировать доставку сообщений слишком медленно в распределённой отказоустойчивой системе.
## Backpressure
- процесс разбухания очередей в потоке из-за более быстрого поступления данных, чем их обработки
- техники обработки:
	- перестать читать данные с источника - *stop consume*
    - перестать писать данные в источник - *stop produce*
    - заворачивать поток необработанных данных в отдельный flow
    - автоматеческое масштабирование - усилить compute, развернуть доп. партиции в топике
    - *Reactive Streams* придуман специальный алгоритм взаимодействия producer и consumer, согласно которому consumer сообщает сколько сообщений он готов прочитать (поддерживается в nifi, def 10 000 FlowFiles or 1Gb )
    - также в *NIFI* есть механизмы/модели прогнозирования Backpressure
## State Management
- в потоковой обработке выделяют 2 подхода:
	- *Statefull* - с сохранением промежуточного состояния т.е. учитываются другие данные потока (напр. дедупликация)
		- очевидно при Statefull нам нужно сохранять состояние и обращаться к общему storage с разных узлов
    - *Stateless* - каждое сообщение обрабатывается независим
# Архитектуры
## Lambda  
2011
- состоит из *Batch layer* и *Stream layer*
- *Batch layer* (t-1) - пакетна обработка исторических данных, отказоустойчивая, достоверная и надежная. Но с большой задержкой. Часто реализовано в DL.
- *Stream layer* (t) - поток real time событий, возможны потери, дубли, неточности, и нестабильная работа
- данные постепенно заполняются в Batch layer и удаляются из Stream layer
- когда нужна интерактивная предиктивная аналитика на базе исторического бэкграунда
- оба потока объединяются в конце ( в т.ч. виртуально), в сервисном уровне - получаем историчные и максимально свежие данные
- главный поинт в единой точке доступа к t и t-1 данным (kafka + субд)
- трудоёмкость, дублирование обрабоки однордных данных разными стеками и технологиями. В т.ч. необходимо держать инфраструктуру.
- качество данных в batch и stream сильно отличается и бизнес требует согласования, что невозможно архитектурно
## Kappa
2014
- только stream поток (t)
- несколько потоков пишут события в неизменяемый log/журнал, в этом месте события сортируются и приводятся в хронологический порядок
- сервисный уровень, где этот log обрабатывается (выбирается последнее состояние) обогащается справочными данными, переносится в место удобное для доступа пользователям
- сервисный уровень - любая субд, log - kafka топик без очитски
- любое изменение задним числом - перегрузка объекта сервисного уровня, что затруднительно при больших объемах
## Delta
- как Lambda, только Batch и Stream пишут в DLH, что убирает некоторые минусы Lambda, такие как специальный сервисный уровень для объединения B и S
## Коробочные решения streaming ETL  
все готовые решения - облачные, есть отдельные сервисы для IoT, Lambda и Kappa.
* *Yandex Cloud: Data Stream* - приём данных из источников через брокеры сообщений и приземление в S3/CH через Data Transfer
* *Arenadata Streaming*: kafka, nifi, zookeeper
* *Google cloud Datastream*: 
* *Azure*
* *AWS* (богаче всех)
# Технологии и фреймворки
## Apache Flink(Unicorn)
- работает с таблицами и потоками через *Flink Table API*.
- таргет - таблица, файл или брокер сообщений
- горизонтально масштаблируетсяя за счет параллелизма задач. Алгоритм асинхронной инкрементальной контрольной точки
- неограниченный поток - сообщения читаются и обрабатываются по мере поступления, логически не важен порядок поступления и обработки сообщений
- ограниченный поток - сообщения синхронизируются и копятся в очереди т.к. нам нужна дедупликация или важен порядок.
- для загрузки и преобразований данные загружаются в память, но могут и на диск
- *DataStream API, Table API и Python API* - 3 способа разработки пайплайнов
- виды *join*: с фиксированным окном, со скользящим окном, можно задать окно для 1 потока, для всех потоков, cross join для всех совпадений внутри и lookup. При window join результат возвращается когда события в окне полностью заполненны. т.е. окно должно быть в прошлом, полностью.
	- *Tumbling Window Join* - задается размер окна, в функцию соединения передаются все пары в рамках окна с совпадающим ключом
	- *Sliding Window Join* - задается не только размер, но и смещение окна, в функцию соединения попадают все пары в рамках окна с совпадающим ключом
	- *Session Window Join* - задается зазор между сессиями, в функцию соединения также попадают все пары с совпадающим ключом
	- *Interval Join* - задаются границы интервала времени и для каждого события первого потока откладывается заданный интервал, соединение происходит если в рамках этого интервала во втором потоке находятся события с совпадающим ключом. На вход функции соединения подаются все пары совпавших событий
- встроенные ML библиотеки, например для фильтрации входящих потоков и поиска антифрода
### Компоненты
#### State Management
- каждый оператор потока может обрабатываться параллельно в несколько потоков на разных серверах
- каждому оператору можно задать степень ||, тогда автоматически будет запускаться нужное количество слотов/тасков
- где может хранится State: JVM и где угодно
- *Keyed state* - состояние привязанное к ключам. т.е. доступно для всех записей потока с определенным значением ключа
- *Operator state* - хранит сосотяние на уровне опертора
#### Сheckpoints и Savepoints
- *Сheckpoints* - на случай восстановления после сбоя, *Savepoints* - на случай редеплоя потока (изменение)
- согласованная на уровне потока копия State каждого Task
- каждый таск имеет свой offset
- с какой-то периодичностью записывается согласованное состояние всех Offset и State всех Task
#### Watermark
- метка date-time сообщения. показывает сколько сообщение висит в потоке
- имеет вид выражения, возвращающего timestamp
- может принимать значение из атрибута сообщения
- определяет насколько сообщения могут запаздывать, каждый раз про прохождении через оператор проверяется значение watermark, на предмет допустимо ли обрабатывать это сообщение.
- при прохождении через оператор - сообщение через watermark сообщает ему что все сообщения с более ранними watermark получены
- запоздалые данные могут быть отправлены в отдельный stream, буфферизированны или произнорированны
