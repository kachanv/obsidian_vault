Далее расматривается програмная оптимизация джобов, и немного затрагивается тюнинг настроек в рамках *application*
## Общие рекомендации
* утверждается что использование *Structured API* быстрее чем *RDD* в силу встроенных оптимизаций
* *UDF* лучше писать на Java/Scala (см. [[3. Structured API#User-Defined Functions]] )
* *shuffle* - дорогая операция
* когда *executor*-у не хватает памяти он может начать спилить на диск
* в *Structured API* spark автоматически делает push down предикатов (во многих случаях)
* чтобы получить максимальную параллельность операций следует количество *partition* делать > количество *executor* * количество ядер на 1 *executor*. Следует помнить на 1 *partition* может параллельно выполняться 1 *task*. Общая рекомендация иметь 2-3 *task* на 1 ядро *executor*.
* есть встроенные оптимизации от перекосов по null => не стоит использовать дефолтные значения вместо null ('','N/A' etc.)
* первопричина проблем с перекосами (по null и по данным) между *executors* такая же как в GP, особенно при группировках и join-ах. 
* некоторые аггрегирующие f-ии медленнее прочих (*collect_list*, *collect_set*) т.к. они делают *collect* на *driver*
*  следует внимательно следить за типами, по умолчанию *spark* не сообщает об ошибках автоматического приведения типов и возвращает null:  `SELECT 5 * " "` возвращает *null*
* использование *RDD* API с Python влечет за собой высокий overhead по сериализации объектов
* некоторые кодеки сжатия такие как ZIP не позволяют читать файл параллельно
* ошибка *Driver* `OutOfMemoryError` - очевидно говорит о том что на нем кончилась память => вероятно был запущен *collect* большого куска данных | в больших *Application* возможно накопление мусора от *JVM*. **Важно:** в отличие от *executor* падение *driver* приводит к полной остановке *application*
* *repartition* перед  *join* может быть полезно, но следует помнить что *repartition* также не бесплатная операция
* *spark.speculation=true* запускает при чтении данных дополнительный task, но это может привести к дублированию данных (`?`)
## Analyze
**Опр:** позволяет оптимизатору строить корректные планы запросов исходя из характера данных
* spark не собирает статистику сам на регулярной основе (т.к. это инструмент compute)
* речь про сбор статистики над промежуточными данными джоба, статистика которая лежит в parquet/iceberg используется spark-ом он она должна обновляться отдельно.
* есть 2 уровня статистики: *table* и *column*
	* *table* - собирает размер таблицы в строках и байтах, делает full scan таблицы: `ANALYZE TABLE my_table COMPUTE STATISTICS`
		* можно собрать на отдельную партицию
		* можно собрать только размер в байтах используя `NOSCAN`, но не делая full scan
	*  *column* - собирает статистику на колонку: `ANALYZE TABLE my_table COMPUTE STATISTICS FOR COLUMNS my_column [ALL COLUMNS]`
		*  считает: count null | min | max | count distinct | histogram (отключено по дефолту)
		* может менять план у join | агрегаций
## Partitions
**Опр:** управление партицированием данных **во время выполнения** spark application. 
* *repartition* - изменение кол-ва партиций. Можно задать количество партиций + поле, или что-то одно. Приводит к *shaffle*
	* увеличить параллельность операций
	* избавиться от перекосов перед join | агрегацией
	* уменьшить количество партиций перед записью
	* уменьшить количество и при этом получить на выходе равномерные партиции
* *coalesce* - схлапывание партиций. Задается только количество партиций.
	* старается схлопнуть смежные партиции по возможности чтобы избежать *shaffle* т.е. партиции на одной ноде кластера
	* в результате партиции могут полуиться не равноменрые по объему т.к. приоритет в том чтобы избежать *shaffle*
* *rebalance* - разбивает на +- равные партиции сглаживая перекосы
	* приводит к *shaffle* но не полному
	* принимает такие же аргументы как *repartition*
* используется для локальных join | аггрегаций
* на все эти операции есть хинты в *SparkSQL*
## Cashing
**Опр:** сохранение данных в памяти (def) или на диске узла кластера для переиспользования.
* `cache()` | `persist()`
* use case: выгрузка и очистка данных с последующим использованием в разных расчетах в рамках одного *application*. Когда над одним набором данных выполняется несолько *action*
* lazy operation: кэширование произойдет только после первого *action*.
* overhead на сериализацию/десериализацию
* spark использует **LRU** политику т.е. может удалять из кэш партиции которые не используются, при заполнении памяти
* в плане запроса использование кэша выглядит как `InMemory`
## План запроса
`EXPLAIN [ EXTENDED | CODEGEN | COST | FORMATTED ] statement`
* запрос не выполняется во время вызова `EXPLAIN` (с любыми модификаторами). Если нужен фактический план выполнения нужно использовать *SparkUI*
* выполняется чтение метаданных
* `EXPLAIN` - физический план запроса
	* читается аналогично SQL
* `EXTENDED` - добавляет 3 логических плана, содержит только и вид операции и их последовательноть (без shuffle и типов джоина)
	* *Parsed* - запрос разбитый на граф выполнения операций (в лоб)
	* *Analyzed* - предыдущий план сопоставленный с данными 
	* *Optimized* - предыдущий план обработанный оптимизатором
* `CODEGEN` - генерирует java код для каждого этапа наполнения
* `COST` -  добаяляет в логический план количество строк и байт
* `FORMATTED` - включает сразу все вышеперечисленное + push down предикатов + красиво отформатированно
### Что можно увидеть в плане
из не очевидного
* *number of output rows* показываются в рамках 1 партиции а не всего файла
* *shuffle* обозначается в плане как `Exchange`. В скобках пишется поле и количество партиций. 
* если в плане запроса операция чтения помечена как `local` это означает что executor читает данные сохраненные непосредственно на узле Spark кластера
* `pushedFilters` - pushDown предикатов
* `Project` - select определенных колонок
* `Expand` - мульти group by например *Cube*
* `Batched: true` - векторное чтение для форматов файлов Parquet и т.п.
* `*(1)` - подобная информация в плане говорит об этапах кодогенерации. Это не этапы выполнения плана. Это значит что для стадий плана помеченных `*(1)` код будет сгенерирован вместе.
