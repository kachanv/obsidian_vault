**Опр:** интерфейс получения доступа к внешним данным из-под GP  
Основные параметры - формат и локация/протокол
Поддерживаются *Readable* и *Writable* внешние таблицы.
- существуют _WEB TABLE_ - скрипт/сервис которое на каждом сегменте принимает поток данных и обрабатывает их самостоятельно
```
=# CREATE WRITABLE EXTERNAL WEB TABLE output (output text) 
EXECUTE 'export PATH=$PATH:/home/`gpadmin` 
		/programs; myprogram.sh' 
FORMAT 'TEXT' DISTRIBUTED RANDOMLY;
```
т.о. на стороне gp - *WEB TABLE* интерфейс доступа к потоку данных
* *WRITABLE EXTERNAL TABLE* - имеет опциональную настройку DISTRIBUTED, которая хорошо бы совпадала с распределением выгружаемой таблицы gp, чтобы избежать движения данных
# Протоколы (Location)
## file
```LOCATION ('file://host1:5432/data/expense/*.csv', 'file://host2:5432/data/expense/*.csv', 'file://host3:5432/data/expense/*.csv')```
* путь к файлу на сегменте
* параллелизм достигается разделением файла по сегментам
* максимум на хосте может быть столько же файлов сколько первичных сегментов
* только *Readable*
## gpfdist
*Опр:* Greenplum Parallel File Server
* утилита, для параллельной записи и чтения на удаленных серверах. gpfdist соответственно ставится на этих серверах
* можно указывать несколько файлов/хостов
* протокол http, с сжатием
* все сегменты имеют параллельный доступ к файлу, по умолчанию хост host gpfdist может поддерживать до 64 параллельных подключений от сегментов
* можно как писать так и читать данные с gpfdist из gp
* *gpfdists* - gpfdist c SSL (https)
* если писать в внешнюю *WRITABLE* таблицу с помощью *gpfdist* можно указывать несколько файлов/хостов. Тогда данные при записи размажутся по файлам.
* В TK созданы отдельные контуры для gpfdist для загрузки и выгрузки данных из GP, примонтированы в папке ramdisk со свои набором портов
- gpfdist не удаляет файлы после их создания на хосте
- gpfdist может распаковать gzip и bzip2 автоматически. Читать и писать gpfdist способен в любые файлы тестового формата в т.ч. XML и JSON
## gphdfs
* deprecated, рекомендуется использовать pxf
## s3
* можно как писать так и читать данные
* параллельный доступ со всех сегментов
* ручная настройка протокола, с заведением конфига на каждом сегменте, созданием протокола через CREATE PROTOCOL (как и для любого кастомного протокола)
* LOCATION задается в формате S3, можно указать только 1
* при вставке данных из gp в s3, на стороне s3 каждый сегмент создаст свой файл
## pxf
* кастомный протокол для доступа (чтение/запись) к внешним системам (HDFS, СУБД, S3 etc.)
* поддерживает форматы записи данных: *text*, *binary*, and *parquet-format*
* использует разные коннекторы для разных внешних систем, параллельное чтение и запись зависят от коннектора.
* master творит план запроса и рассылает его на сегменты, с сегментов проксируется на PXF сервер, установленный на каждом сегменте, далее через коннекторы отправляется запрос во внешнюю систему.
## custom protocol
* можно использовать свой протокол
# FORMAT
## Custom
```FORMAT 'CUSTOM' (formatter=format_function, key1=val1,...keyn=valn)```
- *formatter* - функция форматирования пользовательского типа данных
- речь про текстовые форматы
- можно задать ширину(размер) и формат данных с помощью *formatter=fixedwidth_in*
```
CREATE READABLE EXTERNAL TABLE students ( name varchar(20), address varchar(30), age int) 
LOCATION ('file://<host>/file/path/') 
FORMAT 'CUSTOM' (formatter=fixedwidth_in, name='20', address='30', age='4');
```
также можно задать нульность полей, дефолтные значения, разделители, перносы строк и т.д.:
- READABLE - formatter=fixedwidth_in | WRITABLE EXTERNAL - formatter=fixedwidth_out
- _preserve_blanks_=off - rtrim пробелов
- _null_='null_string_value' - замена null
- _line_delim_='line_ending' - разделитель строк