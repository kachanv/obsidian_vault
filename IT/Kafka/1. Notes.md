https://github.com/kachanv/simple_kafka

**Глоссарий:**
- *confluent schema regestry* - топик kafka с compaction
## Kafka Consumer
- `Какие модули языка можно использовать?`
    - нативный Java клиент
        - Producer API - складывать сообщения в топик (есть на python)
        - Consumer API - читать из топика (есть на python)
        - Streams API - читать из топика трансформировать и перекладывать в другой топик
        - Connect API - напрямую подключиться к источнику
        - Admin API - утправлять брокером (есть на python)
    - **PyKafka**
        - python way библиотека с подключаемой C librdkafka, последний релиз 2018
    - **Kafka-Python**
        - python api, похож на оффициальный java клиента kafka
        - синхронный/асинхронный продюсер
        - последний релиз 2020
    - **Confluent Python Kafka**
        - обертка вокруг librdkafka, производительность высокая на уровне java, +- python way api поверх
        - последний релиз 2023
        - синхронный/асинхронный продюсер
        - сложный дебаг ошибок C
    - **aiokafka**
        - true асинхронный неблокирующий клиент kafka, Java клиент расчитан на многопоточность но в общем то он синхронный
        - => попытка мимикрировать под него средствами python моздает однопоточный синхронный клиент. aiokafka - пытается реализовать true асинхронный API kakfa
        - "Apache Kafka client for asyncio"
        - под капотом использует kafka-python

- `В каком формате kafka передает данные`  
    - в бинарном. Тело собщения должно быть binary, ключ сообщения может быть строкой
    - kafka роботает по принципу SerDe, чтобы отправить сообщения его нужно сериализовать, чтобы прочитать - десериализовать

## Аутентификация в Kafka
* нет аутентификации + нет шифрования 
    - security.protocol=PLAINTEXT
* аутентификация по паролю/нет шифрования
        - security.protocol=SASL_PLAINTEXT
        - параметры sasl.jaas.config
* Какие варианты аутентификации есть в Kafka?
    - можно настроивать как межброкерное соединение так и соединение брокер - клиент
    
    - TLS/SSL шифрование + SASL аутентификация                                     
	    - в конфиге брокера и клиента: security.protocol=SASL_SSL
	    - настройки                                              
	        * настроить хранилище ключа и сертификата
			* выбрать конкретный механизм авторизации SASL
			* на брокере: sasl.enabled.mechanisms=PLAIN
			* настроить адрес и порт протокола аутентификации
			* на клиенте: sasl.mechanisms=PLAIN
			* задать параметры sasl.jaas.config
        что такое SASL                                                             Simple Autentification and Securiry Level
                                                                                   фреймворк позволяющий прикладным протоколам проводить аутентификацию. По сути позволяет участникам соединения договорится о об использования какого-либо механизма аутентификации
        механизмы аутентификации SASL                                              
                                                                                   PLAIN - user/password хранятся в конфиге kafka
                                                                                   GSSAPI - Kerberos (участникам соединения направляются симметричные ключи от центра ключей, отдельного физ. сервера)                         
                                                                                   SCRAM - 
                                                                                   OAUTHBEARER - 
                                                                                   LDAP - 

	    - TLS/SSL шифрование + TLS/SSL аутентификация                                  в конфиге брокера и клиента: security.protocol=SSL
        настройки                                                                  настроить хранилище ключа и сертификати
        как происходит аутентификация                                              брокер/клиент проверяют сертификат участника соединения в удостоверяющем центре

## Аутентификация в Kafka
- как писать данные через CLI kafka-console-producer.sh + топик + адрес брокера. Всего у команды 21 параметр: размер батча, сериалайзер, количество ретраев отправки сообщения, acks(0,1,2), таймауты, сепаратор ключа
- дефолтный механизи распределения по партициям без ключа Sticky Partitioner: копим полный батч - отправляем в партицию, следующий батч в следующую партицию т.о. отправляем полные батчи а не огрызки как в round robin
- продюсер отправляет по 1 сообщению за раз ? отправляет по батчу т.е. копит в буфере перед отправкой.
- из чего состоит соощение kafka (ProducerRecord)(5) топик + сообщение + партиция(опционально) + ключ(опционально) + хедер(опционально)
- какие семантики доставки существуют acks = 0 | 1 | -1 0-at most once | 1-ждем подтверждения только от leader | -1(all) ждем подтверждения от лидера и от ISR реплик (потери невозможны, в остальных возможны)

* что происходит под капотом продюсера при отправке сообщения(7)                   1 - read мета в зукипере: адреса брокеров кластера, их адреса, лидеры партиций. Тяжелая блокирующая операция => не нужно создавать продюсера на каждую отправку сообщений
                                                                                   2 - формируется ProducerRecord
                                                                                   3 - сериализация (key.sereilizer | value.sereilizer )
                                                                                   4 - выбор партиции (по key, в определенную партицию, sticky partitioner, round robin) и прикрепление этой инфы к ProducerRecord
                                                                                   5 - compress сообщения
                                                                                   6 - складываем в батч, когда батч накопится или истечет linger.ms - отправляем батч
                                                                                   7 - брокер возвращает RecordMetadata(топик, партиция, оффсет) если запись успешна или исключение
* сериализуется только value или key тоже ?                                        сериализуются оба причем допустимы разные сериализаторы
* в чем разница синхронной и асинхронной отправки                                  синхронная - отправка->ожидание ответа->следующая отправка (часть времени продюсер ждет ответ брокера, остальные сообщения ждут)
                                                                                   асинхронная - нет ожидания ответа т.к. каждая отправка ждет свой ответ независимо
* продюсер может отправить весь пул сообщений асинхронно                           нет, количество сообщений "in flight" т.е. без статуса доставки регулируется max.in.flight.requests.per.connection
* основные параметры продюсера(8)
    - acks                                                                         1 - ждет потверждения записи от leader partiton, возможны потери (лидер получил сообщение, отправил ответ об успехе и сдох до отправки копии на реплики)
                                                                                   0 - отправил и забыл. Высочайшая скорость, возможны потери
                                                                                  -1(all) - ждет потверждения записи от leader partiton и insinc реплик. Количество реплик зависит от настройки replication factior на топике или брокере
    - client.id                                                                    к сообщению прикрепляется строка предназначенная для идентификации сообщений с определенного консюмера в топике (например в 1 топик пишет несколько приложений)
    - retries                                                                      количество попыток повторной отправки сообщения в случае возврата ошибки от брокера
    - request.timeout.ms                                                           сколько времени продюсер будет ждать ответ об успешной записи сообщения от продюсера
    - compression.type                                                             алгоритм сжатия (по умолчанию нет сжатия)
    - batch.size                                                                   размер батча
    - linger.ms                                                                    интервал отправки батчей (отправится даже неполный батч)
    - max.in.flight.requests.per.connection                                        количество асинхронно отправляемых сообщений до получения ответа от брокера (=1, будет реализована синхронная отправка)

* как реализована exactly once семантика                                           нужно задать в продюсере idempotence=true - гарантия что в партицию топика запишется только 1 экземпляр сообщения
                                                                                   acks = all
                                                                                   retries > 0
                                                                                   max.in.flight.requests.per.connection <=5
                                                                                   реализовать запись сообщения строго в одну и ту же партицию (через key)
* Алгоритм работы KafkaLoader в GP создается EXTERNAL TABLE из неё выгружается в json

                                                                              из СхемаРеджисти получаем схему
                                                                              создается очередь, безопасная для работы нескольких процессов
                                                                              каждый процесс в очереди сериализует и отправляет сообщение

## AVRO в сообщениях в Kafka                         
 - почему авро легковестный ?                                                      JSON дублирует структуру в каждом сообщении, AVRO держит структуру в схеме а передает только данные
 - уровни совместимости схем                                                       BACKWARD - можно удалять поля, добавлять nullable поля, сравнение идет с последней версией схемы, первыми схему обновляют консюмеры
                                                                                   FORWARD - можно добавлять поля, удалять nullable поля, сравнение идет с последней версией схемы, первыми схему обновляют продюсеры
                                                                                   FULL - можно добавлять/удалять nullable поля, сравнение идет с последней версией схемы, любой порядок обновления
                                                                                   NONE - нет проверки на совместимость
                                                                                   + для каждого уровня (кроме NONE) есть вариант с проверкой всех версий схем а не последней

